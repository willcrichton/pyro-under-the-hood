{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:23:35.441247Z",
     "start_time": "2019-06-11T20:23:35.246141Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "from pyro import sample\n",
    "from torch import tensor\n",
    "\n",
    "# A fair coin\n",
    "coinflip = sample(\"coinflip\", dist.Bernoulli(probs=0.5))\n",
    "print('coinflip', coinflip)\n",
    "\n",
    "# A noisy sample\n",
    "noisy_sample = sample(\"noisy_sample\", dist.Normal(loc=0, scale=1))\n",
    "print('noisy_sample', noisy_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:23:35.449429Z",
     "start_time": "2019-06-11T20:23:35.443804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating probability of values under distributiosn\n",
    "print('X ~ B(0.5), P(X = 0): {:.2f}'.format(\n",
    "    dist.Bernoulli(0.5).log_prob(tensor(0.)).exp()))\n",
    "print('X ~ N(0, 1), P(X = 0.35): {:.2f}'.format(\n",
    "    dist.Normal(0, 1).log_prob(tensor(0.35)).exp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:23:35.465459Z",
     "start_time": "2019-06-11T20:23:35.452063Z"
    }
   },
   "outputs": [],
   "source": [
    "def sleep_model():\n",
    "    # Very likely to feel lazy\n",
    "    feeling_lazy = sample(\"feeling_lazy\", dist.Bernoulli(0.9))\n",
    "    if feeling_lazy:\n",
    "        # Only going to (possibly) ignore my alarm if I'm feeling lazy\n",
    "        ignore_alarm = sample(\"ignore_alarm\", dist.Bernoulli(0.8))\n",
    "        # Will sleep more if I ignore my alarm\n",
    "        amount_slept = sample(\"amount_slept\",\n",
    "                              dist.Normal(8 + 2 * ignore_alarm, 1))\n",
    "    else:\n",
    "        amount_slept = sample(\"amount_slept\", dist.Normal(6, 1))\n",
    "    return amount_slept\n",
    "\n",
    "print(sleep_model())\n",
    "print(sleep_model())\n",
    "print(sleep_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:23:35.477132Z",
     "start_time": "2019-06-11T20:23:35.468975Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "class Bernoulli:\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "        \n",
    "    def sample(self):\n",
    "        # random() is uniform between [0, 1]\n",
    "        if random() < self.p:\n",
    "            return tensor(1.)\n",
    "        else:\n",
    "            return tensor(0.)\n",
    "        \n",
    "    def log_prob(self, x):\n",
    "        # This formulation is differentiable!\n",
    "        return (x * self.p + (1 - x) * (1 - self.p)).log()\n",
    "    \n",
    "b = Bernoulli(0.8)\n",
    "print('x ~ P_b:', b.sample())\n",
    "print('P_b(0):', b.log_prob(tensor(0.)).exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:23:35.493020Z",
     "start_time": "2019-06-11T20:23:35.478829Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyro.poutine import trace\n",
    "from pprint import pprint\n",
    "\n",
    "# Runs the sleep model once and collects a trace\n",
    "tr = trace(sleep_model).get_trace()\n",
    "\n",
    "pprint({\n",
    "    name: {\n",
    "        'value': props['value'],\n",
    "        'prob': props['fn'].log_prob(props['value']).exp()\n",
    "    }\n",
    "    for (name, props) in tr.nodes.items()\n",
    "    if props['type'] == 'sample'\n",
    "})\n",
    "\n",
    "print(tr.log_prob_sum().exp()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:23:35.509148Z",
     "start_time": "2019-06-11T20:23:35.494431Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyro import condition\n",
    "\n",
    "cond_model = condition(sleep_model, {\n",
    "    \"feeling_lazy\": tensor(1.),\n",
    "    \"ignore_alarm\": tensor(0.),\n",
    "    \"amount_slept\": tensor(10.)\n",
    "})\n",
    "\n",
    "trace(cond_model).get_trace().log_prob_sum().exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:25:19.149975Z",
     "start_time": "2019-06-11T20:25:18.333565Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "traces = []\n",
    "for _ in range(1000):\n",
    "    tr = trace(sleep_model).get_trace()\n",
    "    values = {\n",
    "        name: props['value'].item()\n",
    "        for (name, props) in tr.nodes.items()\n",
    "        if props['type'] == 'sample'\n",
    "    }\n",
    "    traces.append(values)\n",
    "\n",
    "pd.DataFrame(traces).hist()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:31:49.693321Z",
     "start_time": "2019-06-11T20:31:49.688838Z"
    }
   },
   "outputs": [],
   "source": [
    "norm = dist.Normal(0, 1)\n",
    "x = sample(\"x\", norm)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:33:46.493426Z",
     "start_time": "2019-06-11T20:33:46.487446Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyro import param\n",
    "\n",
    "mu = param(\"mu\", tensor(0.))\n",
    "norm = dist.Normal(mu, 1)\n",
    "x = sample(\"x\", norm)\n",
    "print(mu, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:34:26.202773Z",
     "start_time": "2019-06-11T20:34:26.192476Z"
    }
   },
   "outputs": [],
   "source": [
    "prob = norm.log_prob(5)\n",
    "print('Initial prob:', prob, prob.exp())\n",
    "\n",
    "prob.backward() # Compute gradients with respect to probability\n",
    "\n",
    "print('mu:', mu)\n",
    "print('d mu / d prob:', mu.grad) # 5.0\n",
    "mu.data += mu.grad # Manually take gradient step\n",
    "\n",
    "print('Final prob:', dist.Normal(mu, 1).log_prob(5).exp()) \n",
    "print('Final mu:', mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:35:27.924546Z",
     "start_time": "2019-06-11T20:35:27.916748Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyro import clear_param_store\n",
    "\n",
    "# Note: params are persistent, so we have to manually reset the global Pyro parameter store\n",
    "# to avoid caching results between experiments\n",
    "clear_param_store()\n",
    "\n",
    "def model():\n",
    "    mu = param(\"mu\", tensor(0.))\n",
    "    return sample(\"x\", dist.Normal(mu, 1))\n",
    "\n",
    "cond_model = condition(model, {\"x\": 5})\n",
    "tr = trace(cond_model).get_trace()\n",
    "tr.log_prob_sum().backward()\n",
    "\n",
    "mu = param(\"mu\")\n",
    "mu.data += mu.grad\n",
    "print('Final mu:', mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:37:11.727718Z",
     "start_time": "2019-06-11T20:37:10.876165Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "clear_param_store()\n",
    "\n",
    "def model():\n",
    "    mu = param(\"mu\", tensor(0.))\n",
    "    return sample(\"x\", dist.Normal(mu, 1))\n",
    "\n",
    "model() # Instantiate the mu parameter\n",
    "cond_model = condition(model, {\"x\": 5})\n",
    "\n",
    "# Large learning rate for demonstration purposes\n",
    "optimizer = Adam([param(\"mu\")], lr=0.01)\n",
    "mus = []\n",
    "losses = []\n",
    "for _ in range(1000):\n",
    "    tr = trace(cond_model).get_trace()\n",
    "\n",
    "    # Optimizer wants to push positive values towards zero,\n",
    "    # so use negative log probability\n",
    "    prob = -tr.log_prob_sum()\n",
    "    prob.backward()\n",
    "\n",
    "    # Update parameters according to optimization strategy\n",
    "    optimizer.step()\n",
    "\n",
    "    # Zero all parameter gradients so they don't accumulate\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Record probability (or \"loss\") along with current mu\n",
    "    losses.append(prob.item())\n",
    "    mus.append(param(\"mu\").item())\n",
    "\n",
    "pd.DataFrame({\"mu\": mus, \"loss\": losses}).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:39:13.294995Z",
     "start_time": "2019-06-11T20:39:13.061474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Condition model on observed data\n",
    "underslept = condition(sleep_model, {\"amount_slept\": 6.})\n",
    "\n",
    "# Draw samples from conditioned model?\n",
    "pd.Series(\n",
    "    [trace(underslept).get_trace().nodes['feeling_lazy']['value'].item()\n",
    "    for _ in range(100)]) \\\n",
    "    .hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:39:30.030791Z",
     "start_time": "2019-06-11T20:39:30.024335Z"
    }
   },
   "outputs": [],
   "source": [
    "def sleep_guide():\n",
    "    sample(\"feeling_lazy\", dist.Delta(tensor(1.)))\n",
    "    sample(\"ignore_alarm\", dist.Delta(tensor(0.)))\n",
    "\n",
    "trace(sleep_guide).get_trace().nodes['feeling_lazy']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:42:05.344940Z",
     "start_time": "2019-06-11T20:42:05.326992Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def elbo(guide, cond_model):\n",
    "    dist = 0.\n",
    "    for fl in [0., 1.]:\n",
    "        for ia in [0., 1.] if fl == 1. else [0.]:\n",
    "            log_prob = lambda f: trace(condition(\n",
    "                f, {\"feeling_lazy\": tensor(fl), \"ignore_alarm\": tensor(ia)})) \\\n",
    "                .get_trace().log_prob_sum()\n",
    "            guide_prob = log_prob(guide)\n",
    "            cond_model_prob = log_prob(cond_model)\n",
    "            term = guide_prob.exp() * (cond_model_prob - guide_prob)\n",
    "            if not torch.isnan(term):\n",
    "                dist += term\n",
    "    return dist\n",
    "\n",
    "elbo(sleep_guide, underslept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:42:38.160924Z",
     "start_time": "2019-06-11T20:42:38.152099Z"
    }
   },
   "outputs": [],
   "source": [
    "def sleep_guide2():\n",
    "    sample(\"feeling_lazy\", dist.Delta(tensor(0.)))\n",
    "    sample(\"ignore_alarm\", dist.Delta(tensor(0.)))\n",
    "\n",
    "elbo(sleep_guide2, underslept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:43:17.583170Z",
     "start_time": "2019-06-11T20:43:10.742414Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.distributions import constraints\n",
    "clear_param_store()\n",
    "\n",
    "def sleep_guide():\n",
    "    # Constraints ensure facts always remain true during optimization,\n",
    "    # e.g. that the parameter of a Bernoulli is always between 0 and 1\n",
    "    valid_prob = constraints.interval(0., 1.)\n",
    "    fl_p = param('fl_p', tensor(0.8), constraint=valid_prob)\n",
    "    ia_p = param('ia_p', tensor(0.9), constraint=valid_prob)\n",
    "    feeling_lazy = sample('feeling_lazy', dist.Bernoulli(fl_p))\n",
    "\n",
    "    # Consistent with the model, we only sample ignore_alarm if\n",
    "    # feeling_lazy is true\n",
    "    if feeling_lazy == 1.:\n",
    "        sample('ignore_alarm', dist.Bernoulli(ia_p))\n",
    "sleep_guide()\n",
    "\n",
    "adam = Adam([param('fl_p').unconstrained(), param('ia_p').unconstrained()],\n",
    "            lr=0.005, betas=(0.90, 0.999))\n",
    "param_vals = []\n",
    "\n",
    "for _ in range(2000):\n",
    "    # We can use our elbo function from earlier and compute its gradient\n",
    "    loss = -elbo(sleep_guide, underslept)\n",
    "    loss.backward()\n",
    "\n",
    "    adam.step()\n",
    "    adam.zero_grad()\n",
    "\n",
    "    param_vals.append({k: param(k).item() for k in ['fl_p', 'ia_p']})\n",
    "\n",
    "pd.DataFrame(param_vals).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:44:39.761569Z",
     "start_time": "2019-06-11T20:44:39.757371Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyro.poutine import replay\n",
    "\n",
    "def elbo_approx(guide, cond_model):\n",
    "    guide_trace = trace(guide).get_trace()\n",
    "    model_trace = trace(replay(cond_model, guide_trace)).get_trace()\n",
    "    return model_trace.log_prob_sum() - guide_trace.log_prob_sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:47:26.806818Z",
     "start_time": "2019-06-11T20:47:26.800158Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_guide(elbo):\n",
    "    clear_param_store()\n",
    "    sleep_guide()\n",
    "\n",
    "    adam = Adam([param('fl_p').unconstrained(), param('ia_p').unconstrained()],\n",
    "                lr=0.005, betas=(0.90, 0.999))\n",
    "    param_vals = []\n",
    "    grad_vals = []\n",
    "\n",
    "    for _ in range(2000):\n",
    "        # We can use our elbo function from earlier and compute its gradient\n",
    "        loss = -elbo(sleep_guide, underslept)\n",
    "        loss.backward()\n",
    "        grad_vals.append(param('fl_p').unconstrained().grad.item())\n",
    "\n",
    "        adam.step()\n",
    "        adam.zero_grad()\n",
    "\n",
    "        param_vals.append({k: param(k).item() for k in ['fl_p', 'ia_p']})\n",
    "        \n",
    "    return param_vals, grad_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:48:50.938793Z",
     "start_time": "2019-06-11T20:48:44.178143Z"
    }
   },
   "outputs": [],
   "source": [
    "true_param_vals, true_grad_vals = optimize_guide(elbo)\n",
    "print('Parameters for true ELBO')\n",
    "pd.DataFrame(approx_param_vals).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:48:51.183535Z",
     "start_time": "2019-06-11T20:48:50.970535Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Gradient for true ELBO')\n",
    "pd.Series(true_grad_vals).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:47:30.887559Z",
     "start_time": "2019-06-11T20:47:27.893692Z"
    }
   },
   "outputs": [],
   "source": [
    "approx_param_vals, approx_grad_vals = optimize_guide(elbo_approx)\n",
    "pd.DataFrame(approx_param_vals).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:47:31.352593Z",
     "start_time": "2019-06-11T20:47:31.093689Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(approx_grad_vals).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:49:40.191472Z",
     "start_time": "2019-06-11T20:49:37.457141Z"
    }
   },
   "outputs": [],
   "source": [
    "def elbo_better_approx(guide, cond_model):\n",
    "    guide_trace = trace(guide).get_trace()\n",
    "    model_trace = trace(replay(cond_model, guide_trace)).get_trace()\n",
    "    elbo = model_trace.log_prob_sum() - guide_trace.log_prob_sum()\n",
    "    # \"detach\" means \"don't compute gradients through this expression\"\n",
    "    return guide_trace.log_prob_sum() * elbo.detach() + elbo\n",
    "\n",
    "better_approx_param_vals, better_approx_grad_vals = optimize_guide(elbo_better_approx)\n",
    "pd.DataFrame(better_approx_param_vals).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:49:40.519912Z",
     "start_time": "2019-06-11T20:49:40.234622Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(better_approx_grad_vals).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:50:35.939965Z",
     "start_time": "2019-06-11T20:50:32.850291Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "clear_param_store()\n",
    "adam = Adam({\"lr\": 0.005, \"betas\": (0.90, 0.999)})\n",
    "svi = SVI(underslept, sleep_guide, adam, loss=Trace_ELBO())\n",
    "\n",
    "param_vals = []\n",
    "for _ in range(2000):\n",
    "    svi.step()\n",
    "    param_vals.append({k: param(k).item() for k in [\"fl_p\", \"ia_p\"]})\n",
    "\n",
    "pd.DataFrame(param_vals).plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:50:38.403924Z",
     "start_time": "2019-06-11T20:50:38.341856Z"
    }
   },
   "outputs": [],
   "source": [
    "clear_param_store()\n",
    "\n",
    "def sleep_guide_delta():\n",
    "    is_bool = constraints.boolean\n",
    "    fl = param('fl_p', tensor(1.0), constraint=is_bool)\n",
    "    ia = param('ia_p', tensor(0.0), constraint=is_bool)\n",
    "    feeling_lazy = sample(\"feeling_lazy\", dist.Delta(fl))\n",
    "    if feeling_lazy == 1.0:\n",
    "        sample(\"ignore_alarm\", dist.Delta(ia))\n",
    "\n",
    "svi = SVI(underslept, sleep_guide_delta, adam, loss=Trace_ELBO())\n",
    "svi.step() # NotImplementedError: Cannot transform _Boolean constraints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
